{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VDCNN Implementation In Torch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext import datasets\n",
    "from torchtext import data\n",
    "import nltk\n",
    "import pyprind\n",
    "import math\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENT_LENGTH = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    s = 'abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:’\"/|_#$%ˆ&*˜‘+=<>()[]{} '\n",
    "    return [l for l in list(text.lower()) if l in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = data.Field(\n",
    "    sequential=True,\n",
    "    use_vocab=True,\n",
    "#     init_token=\"<ios>\",\n",
    "#     eos_token=\"<eos>\",\n",
    "    fix_length=SENT_LENGTH,\n",
    "    tokenize=tokenizer,\n",
    "    batch_first=True\n",
    ")\n",
    "label_field = data.Field(\n",
    "    sequential=False,\n",
    "    use_vocab=False,\n",
    "    is_target=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_fields = [\n",
    "    (\"id\", None),\n",
    "    (\"comment_text\", text_field),\n",
    "    (\"toxic\", label_field),\n",
    "    (\"severe_toxic\", label_field), (\"threat\", label_field),\n",
    "    (\"obscene\", label_field), (\"insult\", label_field),\n",
    "    (\"identity_hate\", label_field)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainds, valds = data.TabularDataset.splits(\n",
    "    path=\"data/toxic_competition_data/\",\n",
    "    format=\"csv\",\n",
    "    train=\"train_torch.csv\",\n",
    "    validation=\"test_torch.csv\",\n",
    "    fields=csv_fields,\n",
    "    skip_header=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143613, 15958)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainds), len(valds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence/phrase ----------------- Label\n",
      "hello, thanks message. per wp:noneng, sources languages english also used. let check last source mention, supports state ownership claim, ill add article. regards.  ------------- 0, 0, 0, 0, 0, 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence/phrase ----------------- Label\")\n",
    "for i in range(10):\n",
    "    print(\"{} ------------- {}, {}, {}, {}, {}, {}\".format(\"\".join(trainds.examples[i].comment_text),\n",
    "                                       trainds.examples[i].toxic, trainds.examples[i].insult, trainds.examples[i].identity_hate,\n",
    "                                      trainds.examples[i].obscene, trainds.examples[i].severe_toxic, trainds.examples[i].threat))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(trainds)\n",
    "label_field.build_vocab(trainds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 5183323),\n",
       " ('e', 3987297),\n",
       " ('i', 2626000),\n",
       " ('a', 2492015),\n",
       " ('t', 2366524),\n",
       " ('s', 2201455),\n",
       " ('n', 2166833),\n",
       " ('o', 2041735),\n",
       " ('r', 2019890),\n",
       " ('l', 1648374)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4488, 499)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "traindl, valdl = data.BucketIterator.splits(\n",
    "    datasets=(trainds, valds),\n",
    "    batch_sizes=(BATCH_SIZE, BATCH_SIZE),\n",
    "    sort_key= lambda x: x.comment_text,\n",
    "    repeat=False,\n",
    "    device=device\n",
    ")\n",
    "len(traindl), len(valdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32]\n",
       "\t[.comment_text]:[torch.cuda.LongTensor of size 32x1024 (GPU 0)]\n",
       "\t[.toxic]:[torch.cuda.LongTensor of size 32 (GPU 0)]\n",
       "\t[.severe_toxic]:[torch.cuda.LongTensor of size 32 (GPU 0)]\n",
       "\t[.threat]:[torch.cuda.LongTensor of size 32 (GPU 0)]\n",
       "\t[.obscene]:[torch.cuda.LongTensor of size 32 (GPU 0)]\n",
       "\t[.insult]:[torch.cuda.LongTensor of size 32 (GPU 0)]\n",
       "\t[.identity_hate]:[torch.cuda.LongTensor of size 32 (GPU 0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(traindl.__iter__()); batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_vars):\n",
    "        self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x and y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            if self.y_vars is not None: # we will concatenate y into a single tensor\n",
    "                y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(traindl, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "valid_dl = BatchWrapper(valdl, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[27,  2, 12,  ...,  1,  1,  1],\n",
       "         [23,  3,  6,  ...,  1,  1,  1],\n",
       "         [ 6, 10, 20,  ...,  1,  1,  1],\n",
       "         ...,\n",
       "         [12, 11,  5,  ...,  1,  1,  1],\n",
       "         [ 7, 15, 10,  ...,  1,  1,  1],\n",
       "         [27,  2, 22,  ...,  1,  1,  1]], device='cuda:0'),\n",
       " tensor([[0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]], device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0240f06fe798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mConvolutionalBlockRes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_pool\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class ConvolutionalBlockRes(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=1, shortcut=False, pool_type=\"max_pool\"):\n",
    "        super().__init__()\n",
    "        self.shortcut = shortcut\n",
    "        self.pool_type = pool_type\n",
    "        self.conv_1 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.batch_norm_1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv_2 = nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.batch_norm_2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if shortcut is True:\n",
    "            self.conv_res = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=2)\n",
    "            self.batch_norm_res = nn.BatchNorm1d(out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_1(x)\n",
    "        out = F.relu(self.batch_norm_1(out))\n",
    "\n",
    "        out = self.conv_2(out)\n",
    "        out = F.relu(self.batch_norm_2(out))\n",
    "        \n",
    "        # downsampled\n",
    "        if self.pool_type == \"k_max\":\n",
    "            k_ = math.ceil(out.shape[2]/2.0)\n",
    "            out = downsample_k_max_pool(out, k=k_, dim=2)[0]\n",
    "        else:\n",
    "            out = downsample_max_pool(out, 3, 2)\n",
    "\n",
    "        if self.shortcut is True:\n",
    "            residual = self.conv_res(x)\n",
    "            residual = F.relu(self.batch_norm_res(residual))\n",
    "            out = out + residual\n",
    "        return out\n",
    "\n",
    "class ConvolutionalIdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size, padding=1, shortcut=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.shortcut = shortcut\n",
    "        self.conv_1 = nn.Conv1d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.batch_norm_1 = nn.BatchNorm1d(in_channels)\n",
    "        self.conv_2 = nn.Conv1d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.batch_norm_2 = nn.BatchNorm1d(in_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_1(x)\n",
    "        out = F.relu(self.batch_norm_1(out))\n",
    "\n",
    "        out = self.conv_2(out)\n",
    "        out = F.relu(self.batch_norm_2(out))\n",
    "\n",
    "        if self.shortcut is True:\n",
    "            out = out + x\n",
    "        else:\n",
    "            out = out\n",
    "\n",
    "        return out\n",
    "\n",
    "def downsample_max_pool(x, kernel_size, stride):\n",
    "    pool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride, padding=1)\n",
    "    return pool(x)\n",
    "\n",
    "\n",
    "def downsample_k_max_pool(inp, k, dim):\n",
    "    return inp.topk(k, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VDCNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, n_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(embedding_dim=embedding_dim, num_embeddings=vocab_size)\n",
    "        \n",
    "        self.conv_64 = nn.Conv1d(in_channels=embedding_dim, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.id_64 = ConvolutionalIdentityBlock(64, kernel_size=3, padding=1, shortcut=False)\n",
    "        \n",
    "        self.res_128 = ConvolutionalBlockRes(in_channels=64, out_channels=128, kernel_size=3, padding=1, shortcut=False, pool_type=\"k_max\")\n",
    "        \n",
    "        self.id_128 = ConvolutionalIdentityBlock(128, kernel_size=3, padding=1, shortcut=False)\n",
    "        \n",
    "        self.res_256 = ConvolutionalBlockRes(in_channels=128, out_channels=256, kernel_size=3, padding=1, shortcut=False, pool_type=\"k_max\")\n",
    "\n",
    "        self.id_256 = ConvolutionalIdentityBlock(256, kernel_size=3, padding=1, shortcut=False)\n",
    "        \n",
    "        self.res_512 = ConvolutionalBlockRes(in_channels=256, out_channels=512, kernel_size=3, padding=1, shortcut=False, pool_type=\"k_max\")\n",
    "        \n",
    "        self.id_512 = ConvolutionalIdentityBlock(512, kernel_size=3, padding=1, shortcut=False)\n",
    "        \n",
    "        self.linear_1 = nn.Linear(8*512, 2048)\n",
    "        self.linear_2 = nn.Linear(2048, 2048)\n",
    "        self.linear_3 = nn.Linear(2048, n_classes)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        \n",
    "        # [batch_size, sent_length]\n",
    "        embedded = self.embedding(inp)\n",
    "#         print(embedded.shape)\n",
    "        \n",
    "        # [batch_size, sent_lenght, emb_dim]\n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "#         print(embedded.shape)\n",
    "        \n",
    "        # [batch_size, emb_dim, sent_length]\n",
    "        out = self.conv_64(embedded)\n",
    "#         print(out.shape)\n",
    "        \n",
    "        # [batch_size, 64, sent_length]\n",
    "        out = self.id_64(out)\n",
    "#         print(out.shape)\n",
    "        \n",
    "#         # [batch_size, 64, sent_length]\n",
    "        out = self.res_128(out)\n",
    "#         print(out.shape)\n",
    "        \n",
    "#         # [batch_size, 128, sent_length/2]\n",
    "        out = self.id_128(out)\n",
    "#         print(out.shape)\n",
    "        \n",
    "#         # [batch_size, 128, sent_length/2]\n",
    "        out = self.res_256(out)\n",
    "#         print(out.shape)\n",
    "        \n",
    "#         # [batch_size, 256, sent_length/4]\n",
    "        out = self.id_256(out)\n",
    "#         print(out.shape)\n",
    "        \n",
    "#         # [batch_size, 256, sent_length/4]\n",
    "        out = self.res_512(out)\n",
    "#         print(out.shape)\n",
    "        \n",
    "#         # [batch_size, 512, sent_length/8]\n",
    "        out = self.id_512(out)\n",
    "#         print(out.shape)\n",
    "        \n",
    "#         # [batch_size, 512, sent_length/8]\n",
    "        out = downsample_k_max_pool(out, k=8, dim=2)[0]\n",
    "#         return k_max_pooled\n",
    "#         print(out.shape)\n",
    "        \n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "#         print(out.shape)\n",
    "        # [batch_size, 512, 8]\n",
    "        out = self.linear_1(out)\n",
    "        \n",
    "        # [batch_size, 4096]\n",
    "        out = self.linear_2(out)\n",
    "#         print(out.shape)\n",
    "\n",
    "        # [batch_size, 512, 2048\n",
    "        out = self.linear_3(out)\n",
    "#         print(out.shape)\n",
    "        \n",
    "        # [batch_size, n_class]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "vocab_size = len(text_field.vocab.stoi)\n",
    "n_classes = 6\n",
    "\n",
    "model = VDCNN(embedding_dim, vocab_size, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters in the model are : 16251910\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Number of trainable parameters in the model are : {}\".format(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VDCNN(\n",
      "  (embedding): Embedding(68, 16)\n",
      "  (conv_64): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (id_64): ConvolutionalIdentityBlock(\n",
      "    (conv_1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (res_128): ConvolutionalBlockRes(\n",
      "    (conv_1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_res): Conv1d(64, 128, kernel_size=(1,), stride=(2,))\n",
      "    (batch_norm_res): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (id_128): ConvolutionalIdentityBlock(\n",
      "    (conv_1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (res_256): ConvolutionalBlockRes(\n",
      "    (conv_1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_res): Conv1d(128, 256, kernel_size=(1,), stride=(2,))\n",
      "    (batch_norm_res): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (id_256): ConvolutionalIdentityBlock(\n",
      "    (conv_1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (res_512): ConvolutionalBlockRes(\n",
      "    (conv_1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_res): Conv1d(256, 512, kernel_size=(1,), stride=(2,))\n",
      "    (batch_norm_res): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (id_512): ConvolutionalIdentityBlock(\n",
      "    (conv_1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv_2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (batch_norm_2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (linear_1): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (linear_2): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (linear_3): Linear(in_features=2048, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (preds == y).float()\n",
    "    acc = correct.sum()/float(len(correct))\n",
    "    return acc / 6\n",
    "\n",
    "def roc_auc_score_FIXED(y_true, y_pred):\n",
    "    if len(np.unique(y_true)) == 1: # bug in roc_auc_score\n",
    "        return 0.5\n",
    "    return roc_auc_score(y_true, y_pred)\n",
    "\n",
    "def get_avg_roc_value(y, output):\n",
    "    out = torch.sigmoid(output)\n",
    "    out = out.cpu().detach().numpy()\n",
    "    y = y.cpu().detach().numpy()\n",
    "    \n",
    "    # dividing the predictions according to the siz classes\n",
    "    roc_list = []\n",
    "    for i in range(6):\n",
    "        roc = roc_auc_score_FIXED(y[:, i], out[:, i])\n",
    "        roc_list.append(roc)\n",
    "    \n",
    "    # average \n",
    "    return sum(roc_list) / float(6)\n",
    "\n",
    "def get_avg_roc_value_2(y_fin, output_fin):\n",
    "    n = len(y_fin)\n",
    "    out_list = [[], [], [], [], [], []]\n",
    "    y_list = [[], [], [], [], [], []]\n",
    "    for i in range(n):\n",
    "        for j in range(6):\n",
    "            out_list[j].extend(list(output_fin[i][:, j]))\n",
    "            y_list[j].extend(list(y_fin[i][:, j]))\n",
    "            \n",
    "    roc_list = []\n",
    "    for i in range(6):\n",
    "        roc_list.append(roc_auc_score_FIXED(y_list[i], out_list[i]))\n",
    "    \n",
    "    return sum(roc_list) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_roc = 0\n",
    "    all_y = []\n",
    "    all_out_list = []\n",
    "    \n",
    "    model.train()\n",
    "    bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
    "    for x, y in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x).squeeze(1)\n",
    "        loss = criterion(outputs, y)\n",
    "        acc = binary_accuracy(outputs, y)\n",
    "        roc = get_avg_roc_value(y, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_roc += roc\n",
    "        \n",
    "        all_out_list.append(torch.sigmoid(outputs).cpu().detach().numpy())\n",
    "        all_y.append(y.cpu().detach().numpy())\n",
    "        \n",
    "        bar.update()\n",
    "    roc_main = get_avg_roc_value_2(all_y, all_out_list)\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_roc / len(iterator), roc_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_roc = 0\n",
    "    \n",
    "    all_y = []\n",
    "    all_out_list = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
    "        for x, y in iterator:\n",
    "            outputs = model(x).squeeze(1)\n",
    "            loss = criterion(outputs, y)\n",
    "            acc = binary_accuracy(outputs, y)\n",
    "            roc = get_avg_roc_value(y, outputs)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_roc += roc\n",
    "            \n",
    "            all_out_list.append(torch.sigmoid(outputs).cpu().detach().numpy())\n",
    "            all_y.append(y.cpu().detach().numpy())\n",
    "            \n",
    "            bar.update()\n",
    "    roc_main = get_avg_roc_value_2(all_y, all_out_list)\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_roc / len(iterator), roc_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"data/vdcnn_toxic_model.tar\"\n",
    "def save_checkpoint(state, is_best, filename):\n",
    "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
    "    if is_best:\n",
    "        print (\"=> Saving a new best\")\n",
    "        torch.save(state, filename)  # save checkpoint\n",
    "    else:\n",
    "        print (\"=> Validation loss did not improve\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 01:26:29\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 9.366 | Train ROC: 56.68 | Train Acc: 95.94%\n",
      "| Epoch: 01 | Val. Loss: 0.138 | Val. ROC: 54.31 | Val. Acc: 96.38% |\n",
      "| Train Main ROC: 58.06 | Val. Main ROC: 67.10 \n",
      "=> Saving a new best\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 1\n",
    "base_dev_acc = 0.0\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    train_loss, train_acc, train_roc, train_roc_main = train(model, train_dl, optimizer, criterion)\n",
    "    valid_loss, valid_acc, valid_roc, valid_roc_main = evaluate(model, valid_dl, criterion)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train ROC: {train_roc*100:.2f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'| Epoch: {epoch+1:02} | Val. Loss: {valid_loss:.3f} | Val. ROC: {valid_roc*100:.2f} | Val. Acc: {valid_acc*100:.2f}% |')\n",
    "    print(f'| Train Main ROC: {train_roc_main*100:.2f} | Val. Main ROC: {valid_roc_main*100:.2f} ')\n",
    "    is_best = False\n",
    "    if base_dev_acc < valid_acc:\n",
    "        is_best = True,\n",
    "        base_dev_acc = valid_acc\n",
    "    \n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_loss': valid_loss,\n",
    "        'best_dev_accuracy': valid_acc\n",
    "    }, is_best, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(sentence):\n",
    "    tokenized = tokenize(sentence)\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    \n",
    "    tensor = tensor.unsqueeze(1)\n",
    "#     print(tensor.shape)\n",
    "    prediction = model(tensor).squeeze(1)\n",
    "#     print(prediction)\n",
    "    preds, ind= torch.round(torch.sigmoid(tensor))\n",
    "#     print(preds)\n",
    "    return preds, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"My voice range is A2-C5. My chest voice goes up to F4. Included sample in my higher chest range. What is my voice type?\"\n",
    "# predict_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
