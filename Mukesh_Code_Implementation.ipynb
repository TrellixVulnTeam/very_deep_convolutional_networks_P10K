{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mukesh Code Implementation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "HZzPDGYXjXfF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "luVL689jjxqX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = \"/content/gdrive/My Drive/vdcnn_testing/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qQWB6hRJkCFu",
        "colab_type": "code",
        "outputId": "913c3425-2ba6-4144-fd79-8b3b6bc4cfbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchtext\n",
        "!pip3 install pyprind"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.1 from http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.28.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (0.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.16.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2019.3.9)\n",
            "Requirement already satisfied: pyprind in /usr/local/lib/python3.6/dist-packages (2.11.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RC6sHt0WjxtY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# importing required libraries\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext import datasets\n",
        "from torchtext import data\n",
        "import nltk\n",
        "import pyprind\n",
        "import math\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from string import punctuation\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xVhiB15WkZ2E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvolutionalBlockRes(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, padding=1, pool_type=\"max_pool\"):\n",
        "        super().__init__()\n",
        "        self.pool_type = pool_type\n",
        "        self.conv_1 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1)\n",
        "        self.batch_norm_1 = nn.BatchNorm1d(out_channels)\n",
        "        self.conv_2 = nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, padding=1)\n",
        "        self.batch_norm_2 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv_1(x)\n",
        "        out= F.relu(self.batch_norm_1(out))\n",
        "        out = self.conv_2(out)\n",
        "        out = F.relu(self.batch_norm_2(out))\n",
        "        out = downsample_max_pool(out, 3, 2)\n",
        "        return out\n",
        "\n",
        "def downsample_max_pool(x, kernel_size, stride):\n",
        "    pool = nn.MaxPool1d(kernel_size=kernel_size, stride=stride, padding=1)\n",
        "    return pool(x)\n",
        "\n",
        "\n",
        "def downsample_k_max_pool(inp, k, dim):\n",
        "    return inp.topk(k, dim)\n",
        "\n",
        "class VDCNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, n_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(embedding_dim=embedding_dim, num_embeddings=vocab_size)\n",
        "        self.batch_norm_emb = nn.BatchNorm1d(embedding_dim)\n",
        "        \n",
        "        self.conv_64 = nn.Conv1d(in_channels=embedding_dim, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.batch_norm_conv_64 = nn.BatchNorm1d(64)\n",
        "        \n",
        "        self.res_64 = ConvolutionalBlockRes(in_channels=64, out_channels=64, kernel_size=3, padding=1, pool_type=\"max_pool\")\n",
        "        self.res_128 = ConvolutionalBlockRes(in_channels=64, out_channels=128, kernel_size=3, padding=1, pool_type=\"max_pool\")\n",
        "        self.res_256 = ConvolutionalBlockRes(in_channels=128, out_channels=256, kernel_size=3, padding=1, pool_type=\"max_pool\")\n",
        "        self.res_512 = ConvolutionalBlockRes(in_channels=256, out_channels=512, kernel_size=3, padding=1, pool_type=\"max_pool\")\n",
        "        \n",
        "        self.linear_1 = nn.Linear(3*512, 512)\n",
        "        self.batch_norm_l1 = nn.BatchNorm1d(512)\n",
        "        self.drop1 = nn.Dropout(0.3)\n",
        "        \n",
        "        self.linear_2 = nn.Linear(512, 512)\n",
        "        self.batch_norm_l2 = nn.BatchNorm1d(512)\n",
        "        self.drop2 = nn.Dropout(0.3)\n",
        "        \n",
        "        self.linear_3 = nn.Linear(512, n_classes)\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        # [batch_size, sent_length]\n",
        "        embedded = self.embedding(inp)\n",
        "#         print(embedded.shape)\n",
        "        \n",
        "        # [batch_size, sent_lenght, emb_dim]\n",
        "        embedded = embedded.permute(0, 2, 1)\n",
        "#         print(embedded.shape)\n",
        "        \n",
        "         # batchnorming embeddings\n",
        "        embedded = self.batch_norm_emb(embedded)\n",
        "        \n",
        "        # [batch_size, emb_dim, sent_length]\n",
        "        out = F.relu(self.batch_norm_conv_64(self.conv_64(embedded)))\n",
        "#         print(out.shape)\n",
        "        \n",
        "        # [batch_size, 64, sent_length]\n",
        "        out = self.res_64(out)\n",
        "#         print(out.shape)\n",
        "        \n",
        "        # [batch_size, 128, sent_length/2]\n",
        "        out = self.res_128(out)\n",
        "#         print(out.shape)\n",
        "    \n",
        "        # [batch_size, 256, sent_length/4]\n",
        "        out = self.res_256(out)\n",
        "#         print(out.shape)\n",
        "\n",
        "        # [batch_size, 512, sent_length/8]\n",
        "        out = self.res_512(out)\n",
        "#         print(out.shape)\n",
        "        \n",
        "#         # [batch_size, 512, sent_length/8]\n",
        "        out = downsample_k_max_pool(out, k=3, dim=2)[0]\n",
        "#         print(out.shape)\n",
        "        \n",
        "        out = out.reshape(out.shape[0], -1)\n",
        "#         print(out.shape)\n",
        "        \n",
        "        # [batch_size, 512, 3]\n",
        "        out = F.relu(self.batch_norm_l1(self.linear_1(out)))\n",
        "        out = self.drop1(out)\n",
        "#         print(out.shape)\n",
        "\n",
        "        # [batch_size, 512*3]\n",
        "        out = F.relu(self.batch_norm_l2(self.linear_2(out)))\n",
        "        out = self.drop2(out)\n",
        "#         print(out.shape)\n",
        "\n",
        "        # [batch_size, 512*3]\n",
        "        out = self.linear_3(out)\n",
        "#         print(out.shape)\n",
        "        \n",
        "        # [batch_size, n_class]\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S3oNujfqnDmn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SENT_LENGTH = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M_wjZ_ZFvAt6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenizer(text):\n",
        "    s = 'abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:’\"/|_#$%ˆ&*˜‘+=<>()[]{} '\n",
        "    return [l for l in list(text.lower()) if l in s]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3f25gQktvCN4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text_field = data.Field(\n",
        "    sequential=True,\n",
        "    use_vocab=True,\n",
        "#     init_token=\"<ios>\",\n",
        "#     eos_token=\"<eos>\",\n",
        "    fix_length=SENT_LENGTH,\n",
        "    tokenize=tokenizer,\n",
        "    batch_first=True\n",
        ")\n",
        "label_field = data.Field(\n",
        "    sequential=False,\n",
        "    use_vocab=False,\n",
        "    is_target=True,\n",
        "    dtype=torch.float\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZMfNOqFMvDXt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "csv_fields = [\n",
        "    (\"id\", None),\n",
        "    (\"comment_text\", text_field),\n",
        "    (\"toxic\", label_field),\n",
        "    (\"severe_toxic\", None), (\"threat\", None),\n",
        "    (\"obscene\", None), (\"insult\", None),\n",
        "    (\"identity_hate\", None)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kg7w5ndtvFeS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainds, valds = data.TabularDataset.splits(\n",
        "    path=PATH + \"data/\",\n",
        "    format=\"csv\",\n",
        "    train=\"train_torch.csv\",\n",
        "    validation=\"test_torch.csv\",\n",
        "    fields=csv_fields,\n",
        "    skip_header=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xRsrBOIVvOAN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text_field.build_vocab(trainds)\n",
        "label_field.build_vocab(trainds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Q3_gckdvP3J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pxevbkDUvR0z",
        "colab_type": "code",
        "outputId": "ef32e5ef-2930-4304-9c18-a0b7030e564a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "traindl, valdl = data.BucketIterator.splits(\n",
        "    datasets=(trainds, valds),\n",
        "    batch_sizes=(BATCH_SIZE, BATCH_SIZE),\n",
        "    sort_key= lambda x: x.comment_text,\n",
        "    repeat=False,\n",
        "    device=device\n",
        ")\n",
        "len(traindl), len(valdl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1122, 125)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "MV6xCftkvS5O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class BatchWrapper:\n",
        "    def __init__(self, dl, x_var, y_vars):\n",
        "        self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x and y\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for batch in self.dl:\n",
        "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
        "            \n",
        "            y = getattr(batch, self.y_vars)\n",
        "#             if self.y_vars is not None: # we will concatenate y into a single tensor\n",
        "#                 y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim=1).float()\n",
        "#             else:\n",
        "#                 y = torch.zeros((1))\n",
        "\n",
        "            yield (x, y)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9sRDCwYavU-Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dl = BatchWrapper(traindl, \"comment_text\", \"toxic\")\n",
        "valid_dl = BatchWrapper(valdl, \"comment_text\", \"toxic\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hy64DuGPzxDm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (preds == y).float()\n",
        "    acc = correct.sum()/float(len(correct))\n",
        "    return acc\n",
        "\n",
        "def roc_auc_score_FIXED(y_true, y_pred):\n",
        "    if len(np.unique(y_true)) == 1: # bug in roc_auc_score\n",
        "        return 0.5\n",
        "    return roc_auc_score(y_true, y_pred)\n",
        "\n",
        "def get_avg_roc_value(y, output):\n",
        "    out = torch.sigmoid(output)\n",
        "    out = out.cpu().detach().numpy()\n",
        "    y = y.cpu().detach().numpy()\n",
        "    \n",
        "    roc = roc_auc_score_FIXED(y, out)\n",
        "    return roc\n",
        "\n",
        "def get_avg_roc_value_2(y_fin, output_fin):\n",
        "    n = len(y_fin)\n",
        "    out_list = []\n",
        "    y_list = []\n",
        "    for i in range(n):\n",
        "        out_list.extend(list(output_fin[i]))\n",
        "        y_list.extend(list(y_fin[i]))\n",
        "            \n",
        "    roc = roc_auc_score_FIXED(y_list, out_list)\n",
        "\n",
        "    return roc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GKiyRP8mzxLL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_roc = 0\n",
        "    all_y = []\n",
        "    all_out_list = []\n",
        "    \n",
        "    model.train()\n",
        "    bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
        "    for x, y in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x).squeeze(1)\n",
        "        loss = criterion(outputs, y)\n",
        "        acc = binary_accuracy(outputs, y)\n",
        "        roc = get_avg_roc_value(y, outputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        epoch_roc += roc\n",
        "        \n",
        "        all_out_list.append(torch.sigmoid(outputs).cpu().detach().numpy())\n",
        "        all_y.append(y.cpu().detach().numpy())\n",
        "        \n",
        "        bar.update()\n",
        "    roc_main = get_avg_roc_value_2(all_y, all_out_list)\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_roc / len(iterator), roc_main\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_roc = 0\n",
        "    \n",
        "    all_y = []\n",
        "    all_out_list = []\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
        "        for x, y in iterator:\n",
        "            outputs = model(x).squeeze(1)\n",
        "            loss = criterion(outputs, y)\n",
        "            acc = binary_accuracy(outputs, y)\n",
        "            roc = get_avg_roc_value(y, outputs)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_roc += roc\n",
        "            \n",
        "            all_out_list.append(torch.sigmoid(outputs).cpu().detach().numpy())\n",
        "            all_y.append(y.cpu().detach().numpy())\n",
        "            \n",
        "            bar.update()\n",
        "    roc_main = get_avg_roc_value_2(all_y, all_out_list)\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_roc / len(iterator), roc_main"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OXFLCKZizxRz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8t9LntMNvWOq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_dim = 16\n",
        "vocab_size = len(text_field.vocab.stoi)\n",
        "n_classes = 1\n",
        "\n",
        "model = VDCNN(embedding_dim, vocab_size, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OPFhbMFmvZGa",
        "colab_type": "code",
        "outputId": "ac5b48fd-5b15-4f1c-e057-be93e0114adb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(\"Number of trainable parameters in the model are : {}\".format(params))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trainable parameters in the model are : 2635169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wXORWEyd3IJL",
        "colab_type": "code",
        "outputId": "e8257c4a-8650-4077-90dd-03eb6034ee1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "cell_type": "code",
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VDCNN(\n",
              "  (embedding): Embedding(68, 16)\n",
              "  (batch_norm_emb): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv_64): Conv1d(16, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (batch_norm_conv_64): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (res_64): ConvolutionalBlockRes(\n",
              "    (conv_1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (batch_norm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv_2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (batch_norm_2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (res_128): ConvolutionalBlockRes(\n",
              "    (conv_1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (batch_norm_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv_2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (batch_norm_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (res_256): ConvolutionalBlockRes(\n",
              "    (conv_1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (batch_norm_1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv_2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (batch_norm_2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (res_512): ConvolutionalBlockRes(\n",
              "    (conv_1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (batch_norm_1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv_2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (batch_norm_2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (linear_1): Linear(in_features=1536, out_features=512, bias=True)\n",
              "  (batch_norm_l1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (drop1): Dropout(p=0.3)\n",
              "  (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (batch_norm_l2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (drop2): Dropout(p=0.3)\n",
              "  (linear_3): Linear(in_features=512, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "AXhteFrQwECw",
        "colab_type": "code",
        "outputId": "b3af0dc1-d919-4b34-adab-b02faeaf76b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
        "model.to(device)\n",
        "criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "D0D4N4lvwLFT",
        "colab_type": "code",
        "outputId": "b76b1cbe-1f4a-4246-8dbe-7e1cacbb7061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "MODEL_PATH =PATH + \"data/vdcnn_just_toxic_model_mukesh.tar\"\n",
        "def save_checkpoint(state, is_best, filename):\n",
        "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
        "    if is_best:\n",
        "        print (\"=> Saving a new best\")\n",
        "        torch.save(state, filename)  # save checkpoint\n",
        "    else:\n",
        "        print (\"=> Validation roc did not improve\")\n",
        "    return\n",
        "\n",
        "def load_check_point(model, model_path):\n",
        "    resume_weights = model_path\n",
        "    checkpoint = torch.load(resume_weights)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_accuracy = checkpoint['best_dev_accuracy']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    print(\"Best Dev Accuracy is {}\".format(best_accuracy))\n",
        "    print(\"=> loaded checkpoint '{}' (trained for {} epochs)\".format(resume_weights, checkpoint['epoch']))\n",
        "    return model\n",
        "\n",
        "model = load_check_point(model, MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Dev Accuracy is 0.9618139533996583\n",
            "=> loaded checkpoint '/content/gdrive/My Drive/vdcnn_testing/data/vdcnn_just_toxic_model_mukesh.tar' (trained for 9 epochs)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NUDCPnvfwQgN",
        "colab_type": "code",
        "outputId": "30edd01d-f328-4d56-ccfc-e4922272bcd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 20\n",
        "base_dev_roc = 0.9745\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss, train_acc, train_roc, train_roc_main = train(model, train_dl, optimizer, criterion)\n",
        "    valid_loss, valid_acc, valid_roc, valid_roc_main = evaluate(model, valid_dl, criterion)\n",
        "    \n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train ROC: {train_roc*100:.2f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'| Epoch: {epoch+1:02} | Val. Loss: {valid_loss:.3f} | Val. ROC: {valid_roc*100:.2f} | Val. Acc: {valid_acc*100:.2f}% |')\n",
        "    print(f'| Train Main ROC: {train_roc_main*100:.2f} | Val. Main ROC: {valid_roc_main*100:.2f} ')\n",
        "    is_best = False\n",
        "    if base_dev_roc < valid_roc_main:\n",
        "        is_best = True,\n",
        "        base_dev_roc = valid_roc_main\n",
        "    \n",
        "    save_checkpoint({\n",
        "        'epoch': epoch + 1,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'best_loss': valid_loss,\n",
        "        'best_dev_accuracy': valid_acc\n",
        "    }, is_best, MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:09:29\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.100 | Train ROC: 97.77 | Train Acc: 96.32%\n",
            "| Epoch: 01 | Val. Loss: 0.101 | Val. ROC: 97.02 | Val. Acc: 96.30% |\n",
            "| Train Main ROC: 97.59 | Val. Main ROC: 97.43 \n",
            "=> Validation roc did not improve\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:28\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:12:09\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 02 | Train Loss: 0.096 | Train ROC: 98.02 | Train Acc: 96.40%\n",
            "| Epoch: 02 | Val. Loss: 0.105 | Val. ROC: 96.82 | Val. Acc: 96.09% |\n",
            "| Train Main ROC: 97.83 | Val. Main ROC: 97.47 \n",
            "=> Saving a new best\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:29\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:11:53\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 03 | Train Loss: 0.094 | Train ROC: 98.16 | Train Acc: 96.51%\n",
            "| Epoch: 03 | Val. Loss: 0.103 | Val. ROC: 96.56 | Val. Acc: 96.19% |\n",
            "| Train Main ROC: 97.97 | Val. Main ROC: 97.27 \n",
            "=> Validation roc did not improve\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:29\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:11:55\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 04 | Train Loss: 0.092 | Train ROC: 98.19 | Train Acc: 96.53%\n",
            "| Epoch: 04 | Val. Loss: 0.105 | Val. ROC: 97.11 | Val. Acc: 96.09% |\n",
            "| Train Main ROC: 98.03 | Val. Main ROC: 97.56 \n",
            "=> Saving a new best\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:29\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:11:40\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 05 | Train Loss: 0.091 | Train ROC: 98.32 | Train Acc: 96.56%\n",
            "| Epoch: 05 | Val. Loss: 0.112 | Val. ROC: 96.50 | Val. Acc: 96.11% |\n",
            "| Train Main ROC: 98.16 | Val. Main ROC: 97.15 \n",
            "=> Validation roc did not improve\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:27\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:11:49\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 06 | Train Loss: 0.089 | Train ROC: 98.40 | Train Acc: 96.63%\n",
            "| Epoch: 06 | Val. Loss: 0.105 | Val. ROC: 96.61 | Val. Acc: 96.24% |\n",
            "| Train Main ROC: 98.24 | Val. Main ROC: 97.42 \n",
            "=> Validation roc did not improve\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:28\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:11:47\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 07 | Train Loss: 0.088 | Train ROC: 98.47 | Train Acc: 96.60%\n",
            "| Epoch: 07 | Val. Loss: 0.105 | Val. ROC: 96.95 | Val. Acc: 96.21% |\n",
            "| Train Main ROC: 98.32 | Val. Main ROC: 97.45 \n",
            "=> Validation roc did not improve\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:29\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:11:34\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 08 | Train Loss: 0.086 | Train ROC: 98.53 | Train Acc: 96.72%\n",
            "| Epoch: 08 | Val. Loss: 0.106 | Val. ROC: 96.41 | Val. Acc: 96.26% |\n",
            "| Train Main ROC: 98.38 | Val. Main ROC: 97.20 \n",
            "=> Validation roc did not improve\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:29\n",
            "0% [██████████████                ] 100% | ETA: 00:06:14"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1KHCnpnBzSKk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7FOHq40WzTLv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}